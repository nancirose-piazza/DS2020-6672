import pickle
import numpy as np
import gym
np.random.seed(123) # set a random seed when setting up the gym environment (train_test_split)
import gym_malware
import os
import keras

from keras.models import Sequential
from keras.layers import Dense, Activation, Flatten, ELU, Dropout, BatchNormalization
from keras.optimizers import Adam, SGD, RMSprop

# pip install keras-rl
from rl.agents.dqn import DQNAgent
from rl.agents.sarsa import SarsaAgent
from rl.policy import BoltzmannQPolicy
from rl.memory import SequentialMemory


def generate_dense_model(input_shape, layers, nb_actions, weight=False):
    model = Sequential()
    model.add(Flatten(input_shape=input_shape))
    model.add(Dropout(0.1))  # drop out the input to make model less sensitive to any 1 feature

    for layer in layers:
        model.add(Dense(layer))
        model.add(BatchNormalization())
        model.add(ELU(alpha=1.0))

    model.add(Dense(nb_actions))
    model.add(Activation('linear'))

    savepoint = "gym-malware-master/savepoint"

    if weight:
      latest_weight = sorted( list(os.listdir(savepoint+"/weights")) )[-1]
      model.load_weights(savepoint+"/weights/"+latest_weight)

    if not weight:
      print(model.summary())

    return model


def train_dqn_model(layers, rounds=10000, run_test=False, use_score=False,continue_training=False):
    ENV_NAME = 'malware-score-v0' if use_score else 'malware-v0'
    env = gym.make(ENV_NAME)
    env.seed(123)
    nb_actions = env.action_space.n
    window_length = 1  # "experience" consists of where we were, where we are now



    savepoint = "gym-malware-master/savepoint"
    # generate a policy model
        # configure and compile our agent
    # BoltzmannQPolicy selects an action stochastically with a probability generated by soft-maxing Q values
        # memory can help a model during training
    # for this, we only consider a single malware sample (window_length=1) for each "experience"
    if not continue_training:
      model = generate_dense_model((window_length,) + env.observation_space.shape, layers, nb_actions,weight=False)
      policy = BoltzmannQPolicy()
      memory = SequentialMemory(limit=32, ignore_episode_boundaries=False, window_length=window_length)
    else:
      model = generate_dense_model((window_length,) + env.observation_space.shape, layers, nb_actions,weight=True)
     
      history_saves = sorted (list( os.listdir(savepoint+"/pickle_train")))[-1]
      history_saves = savepoint+"/pickle_train/"+history_saves
      with open(history_saves, 'rb') as f:
        env.history = pickle.load(f)
        f.close()
      policy_dir = sorted( list(os.listdir(savepoint+"/policy") ) )[-1]
      policy_dir = savepoint+"/policy/"+policy_dir
      policy = BoltzmannQPolicy()
      with open(policy_dir,'rb') as f:
        tmp_policy = pickle.load(f)
        policy.tau = tmp_policy['tau']
        policy.clip = tmp_policy['clip']
        f.close()

      memory_dir = sorted( list(os.listdir(savepoint+"/memory") ) )[-1]
      memory_dir = savepoint+"/memory/"+memory_dir
      with open(memory_dir,'rb') as f:
        memory = pickle.load(f)
        f.close()


    # DQN agent as described in Mnih (2013) and Mnih (2015).
    # http://arxiv.org/pdf/1312.5602.pdf
    # http://arxiv.org/abs/1509.06461
    agent = DQNAgent(model=model, nb_actions=nb_actions, memory=memory, nb_steps_warmup=16,
                     enable_double_dqn=True, enable_dueling_network=True, dueling_type='avg',
                     target_model_update=1e-2, policy=policy, batch_size=16)

    # keras-rl allows one to use and built-in keras optimizer
    agent.compile(RMSprop(lr=1e-3), metrics=['mae'])

    # play the game. learn something!
    agent.fit(env, nb_steps=rounds, visualize=False, verbose=2)

    history_train = env.history
    history_test = None
    
    

    if run_test:
        # Set up the testing environment
        TEST_NAME = 'malware-score-test-v0' if use_score else 'malware-test-v0'
        test_env = gym.make(TEST_NAME)

        if continue_training:
          #load in the test history from previous iterations

          pickle_test = sorted ( list(os.listdir(savepoint+"/pickle_test") ) )[-1]
          with open(savepoint+"/pickle_test/"+pickle_test,'rb') as f:
            test_env.history = pickle.load(f)
            f.close()

        # evaluate the agent on a few episodes, drawing randomly from the test samples
        agent.test(test_env, nb_episodes=1000, visualize=False)
        history_test = test_env.history


    policy_dir = list(os.listdir( savepoint+"/policy" ) )
    with open(savepoint+"/policy/policy"+str(len(policy_dir)).zfill(3),'wb') as f:
      pickle.dump(policy.get_config(),f)
      f.close()

    memory_dir = list(os.listdir( savepoint+"/memory" ) )
    with open(savepoint+"/memory/memory"+str(len(memory_dir)).zfill(3),'wb') as f:
      pickle.dump(memory,f)
      f.close()
    

    return agent, model, history_train, history_test


if __name__ == '__main__':
    savepoint = "gym-malware-master/savepoint"

    #create a lot of directories needed..... this should be somewhere in the init of this.
    if not os.path.exists(savepoint):
      os.mkdir(savepoint)
    make_folders = ['weights','pickle_test','pickle_train','memory','policy','models']
    for folder in make_folders:
      if not os.path.exists(savepoint+"/"+folder):
        os.mkdir(savepoint+"/"+folder)


    ## no model weights exists, create a new one.
    if len( os.listdir(savepoint+"/weights") )==0:
      continue_train=False
    else:
      ###training finished for 1 model, training more for another model.
      continue_train=True
    repeat =  5 - (len( os.listdir(savepoint+"/weights") ) % 5)


    for x in range(0,repeat):
      dirlen = len( os.listdir(savepoint+"/weights") )
      agent2, model2, history_train2, history_test2 = train_dqn_model([1024, 256], rounds=10000, run_test=True, use_score=True,continue_training=continue_train)  # allow agent to see scores

      model2.save_weights( savepoint + "/weights/weights"+ str(dirlen).zfill(3) + '.h5', overwrite=True)
     
      with open(savepoint + "/pickle_test/history_score" + str(dirlen).zfill(3) + ".pickle", 'wb') as f:
          pickle.dump(history_test2, f, pickle.HIGHEST_PROTOCOL)

      with open( savepoint +"/pickle_train/history_score_train" + str(dirlen).zfill(3) + ".pickle", 'wb') as f:
          pickle.dump(history_train2, f, pickle.HIGHEST_PROTOCOL)
    
    #save the project to your drive
      os.system("rm gym-malware-master-wip.zip")
      os.system("zip -P password -r gym-malware-master-wip.zip gym-malware-master")
      os.system("cp gym-malware-master-wip.zip drive/My\ Drive/")
      continue_train = True


    modelnum = len ( list ( os.listdir(savepoint +"/models")))
    model2.save(savepoint +"/models/dqn_score"+str(modelnum).zfill(3) +'.h5', overwrite=True)
    
    os.system("rm gym-malware-master-finished.zip")
    os.system("zip -P password -r gym-malware-master-finished.zip gym-malware-master")
    os.system("cp gym-malware-master-finished.zip drive/My\ Drive/")