{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "midterm-nanci-training_model",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWOnMnyjzcCk",
        "colab_type": "code",
        "outputId": "6d71cdd9-a254-4343-b831-5f34ffe14b65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!wget https://github.com/endgameinc/ember/archive/master.zip\n",
        "!unzip master.zip\n",
        "!rm master.zip\n",
        "!cp -r ember-master/* .\n",
        "!rm -r ember-master\n",
        "!pip install -r requirements.txt\n",
        "!python setup.py install"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-05 03:52:32--  https://github.com/endgameinc/ember/archive/master.zip\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/endgameinc/ember/zip/master [following]\n",
            "--2020-04-05 03:52:32--  https://codeload.github.com/endgameinc/ember/zip/master\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.112.10\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.112.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘master.zip’\n",
            "\n",
            "master.zip              [   <=>              ]  11.22M  12.9MB/s    in 0.9s    \n",
            "\n",
            "2020-04-05 03:52:33 (12.9 MB/s) - ‘master.zip’ saved [11769023]\n",
            "\n",
            "Archive:  master.zip\n",
            "04c37efb20ebeb7b99d8ec1d5cdd20ab0328bb36\n",
            "   creating: ember-master/\n",
            "  inflating: ember-master/LICENSE.txt  \n",
            "  inflating: ember-master/README.md  \n",
            "   creating: ember-master/ember/\n",
            "  inflating: ember-master/ember/__init__.py  \n",
            "  inflating: ember-master/ember/features.py  \n",
            "   creating: ember-master/licenses/\n",
            "  inflating: ember-master/licenses/AGPL-LICENSE-3.0.txt  \n",
            "  inflating: ember-master/licenses/MIT-LICENSE.txt  \n",
            "   creating: ember-master/malconv/\n",
            "  inflating: ember-master/malconv/README.md  \n",
            "  inflating: ember-master/malconv/malconv.h5  \n",
            "  inflating: ember-master/malconv/malconv.py  \n",
            "  inflating: ember-master/malconv/multi_gpu.py  \n",
            "  inflating: ember-master/requirements.txt  \n",
            "  inflating: ember-master/requirements_conda.txt  \n",
            "  inflating: ember-master/requirements_notebook.txt  \n",
            "   creating: ember-master/resources/\n",
            "  inflating: ember-master/resources/ember-notebook.ipynb  \n",
            "  inflating: ember-master/resources/ember2018-notebook.ipynb  \n",
            "  inflating: ember-master/resources/logo.png  \n",
            "   creating: ember-master/scripts/\n",
            "  inflating: ember-master/scripts/classify_binaries.py  \n",
            "  inflating: ember-master/scripts/train_ember.py  \n",
            "  inflating: ember-master/setup.py   \n",
            "Collecting lief==0.9.0\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/0e/0d6f3357975dd1530aeb4b4a84a99d493775391758378fb5109f47b613f9/lief-0.9.0.zip\n",
            "Requirement already satisfied: tqdm>=4.31.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (4.38.0)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (1.18.2)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (1.0.3)\n",
            "Requirement already satisfied: lightgbm>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (2.2.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (0.22.2.post1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.2->-r requirements.txt (line 4)) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.2->-r requirements.txt (line 4)) (2018.9)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lightgbm>=2.2.3->-r requirements.txt (line 5)) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.3->-r requirements.txt (line 6)) (0.14.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.24.2->-r requirements.txt (line 4)) (1.12.0)\n",
            "Building wheels for collected packages: lief\n",
            "  Building wheel for lief (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lief: filename=lief-0.9.0-cp36-cp36m-linux_x86_64.whl size=3610316 sha256=7335843076fa8c60d09153f91d400eb13d6c9db7e057720a2f31141417479a47\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/7d/da/deca5cc6d3c5f0d2612e55c691b7c2e57087df18de92733bff\n",
            "Successfully built lief\n",
            "Installing collected packages: lief\n",
            "Successfully installed lief-0.9.0\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating ember.egg-info\n",
            "writing ember.egg-info/PKG-INFO\n",
            "writing dependency_links to ember.egg-info/dependency_links.txt\n",
            "writing requirements to ember.egg-info/requires.txt\n",
            "writing top-level names to ember.egg-info/top_level.txt\n",
            "writing manifest file 'ember.egg-info/SOURCES.txt'\n",
            "reading manifest file 'ember.egg-info/SOURCES.txt'\n",
            "writing manifest file 'ember.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/ember\n",
            "copying ember/__init__.py -> build/lib/ember\n",
            "copying ember/features.py -> build/lib/ember\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/ember\n",
            "copying build/lib/ember/__init__.py -> build/bdist.linux-x86_64/egg/ember\n",
            "copying build/lib/ember/features.py -> build/bdist.linux-x86_64/egg/ember\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ember/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ember/features.py to features.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying ember.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying ember.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying ember.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying ember.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying ember.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/ember-0.1.0-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing ember-0.1.0-py3.6.egg\n",
            "Copying ember-0.1.0-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding ember 0.1.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/ember-0.1.0-py3.6.egg\n",
            "Processing dependencies for ember==0.1.0\n",
            "Searching for scikit-learn==0.22.2.post1\n",
            "Best match: scikit-learn 0.22.2.post1\n",
            "Adding scikit-learn 0.22.2.post1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for lightgbm==2.2.3\n",
            "Best match: lightgbm 2.2.3\n",
            "Adding lightgbm 2.2.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pandas==1.0.3\n",
            "Best match: pandas 1.0.3\n",
            "Adding pandas 1.0.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for numpy==1.18.2\n",
            "Best match: numpy 1.18.2\n",
            "Adding numpy 1.18.2 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tqdm==4.38.0\n",
            "Best match: tqdm 4.38.0\n",
            "Adding tqdm 4.38.0 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for lief==0.9.0\n",
            "Best match: lief 0.9.0\n",
            "Adding lief 0.9.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scipy==1.4.1\n",
            "Best match: scipy 1.4.1\n",
            "Adding scipy 1.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for joblib==0.14.1\n",
            "Best match: joblib 0.14.1\n",
            "Adding joblib 0.14.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for python-dateutil==2.8.1\n",
            "Best match: python-dateutil 2.8.1\n",
            "Adding python-dateutil 2.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pytz==2018.9\n",
            "Best match: pytz 2018.9\n",
            "Adding pytz 2018.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for six==1.12.0\n",
            "Best match: six 1.12.0\n",
            "Adding six 1.12.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for ember==0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wguk7hcNyzf3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_model():\n",
        "  import tensorflow as tf\n",
        "  from tensorflow import keras\n",
        "  from tensorflow.keras import layers\n",
        "  feature_size=2381\n",
        "  tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "  keras.backend.clear_session()\n",
        "  \n",
        "  #Model architecture\n",
        "  from tensorflow.keras import layers\n",
        "  \n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.InputLayer(input_shape=(1,feature_size)))\n",
        "  model.add(layers.Dropout(0.2))\n",
        "  model.add(layers.Dense(1500, activation='relu',activity_regularizer=tf.keras.regularizers.l1(l=0.01)))\n",
        "  model.add(layers.Dropout(0.5))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "  model.compile(tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy',tf.keras.metrics.AUC(),tf.keras.metrics.Precision()])\n",
        "  print(model.summary())\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibCKQVYZy8CQ",
        "colab_type": "code",
        "outputId": "7df51ceb-19de-4642-f5f3-a6dc21f926e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "source": [
        "model = make_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dropout (Dropout)            (None, 1, 2381)           0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1, 1500)           3573000   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1, 1500)           0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1, 1)              1501      \n",
            "=================================================================\n",
            "Total params: 3,574,501\n",
            "Trainable params: 3,574,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WO-a-4Ft0gfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir ember_2017_2\n",
        "!cp -r drive/My\\ Drive/data/ember_2017_2/* ember_2017_2/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNFhGb3WzA3_",
        "colab_type": "code",
        "outputId": "8ffc8c32-bf45-4d22-f9b0-90c06f3bc36a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "import ember\n",
        "X_train, y_train, X_test, y_test = ember.read_vectorized_features(\"ember_2017_2/\")\n",
        "metadata_dataframe = ember.read_metadata(\"ember_2017_2/\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_OZJ4AZCjXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labelrows = (y_train != -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhZGpgH2Co68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train[labelrows]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDEDXTfZHGhE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = y_train[labelrows]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iINPTg2JIiCs",
        "colab_type": "code",
        "outputId": "3cfa2be4-e224-401a-c97a-835cfacd2a40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "len(y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "600000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNKnqF_LFxvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "h5f = h5py.File('X_train.h5', 'w')\n",
        "h5f.create_dataset('X_train', data=X_train)\n",
        "h5f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-7MKh2nHu3F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "h5f = h5py.File('y_train.h5', 'w')\n",
        "h5f.create_dataset('y_train', data=y_train)\n",
        "h5f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hh_DOPo_fs79",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm drive/My\\ Drive/data/ember_2017_2/X_train.dat\n",
        "!rm drive/My\\ Drive/data/ember_2017_2/y_train.dat\n",
        "!cp X_train.h5 drive/My\\ Drive/data/ember_2017_2/\n",
        "!cp y_train.h5 drive/My\\ Drive/data/ember_2017_2/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jdhUB2677b1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "mms = StandardScaler()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXEUvwh78uFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for x in range(0,600000,100000):\n",
        "  mms.partial_fit(X_train[x:x+100000])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvW0HlvkJToE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"drive/My Drive/data/pickles/mms_scaler\",\"wb\") as f:\n",
        "  import pickle\n",
        "  pickle.dump(mms,f)\n",
        "  f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HJvH9L9GyC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "h5f = h5py.File('X_train.h5','r')\n",
        "X_train = h5f['X_train'][:]\n",
        "h5f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pykFqHT3G-jT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = mms.transform(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbc15oKHz-De",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "X_train = np.reshape(X_train,(-1,1,2381))\n",
        "y_train = np.reshape(y_train,(-1,1,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "et14cXjp2fuF",
        "colab_type": "code",
        "outputId": "a77de923-2702-41b1-df93-62295facfa24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "pkl_base=\"drive/My Drive/data/pickles/\"\n",
        "\n",
        "model.compile(tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "          loss='binary_crossentropy',\n",
        "          metrics=['accuracy',tf.keras.metrics.AUC(),tf.keras.metrics.Precision()])\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                batch_size=256,\n",
        "                epochs=1,\n",
        "                  validation_data =((X_train[600000-120000:600000],y_train[600000-120000:600000]))\n",
        "                  )\n",
        "model_name=\"my_model_test-tpu3.h5\"\n",
        "model_weights=\"weights_test-tpu3.h5\"\n",
        "model.save(pkl_base+model_name)\n",
        "model.save_weights(pkl_base+model_weights)\n",
        "print(model_name,model_weights,\" are saved.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 600000 samples, validate on 120000 samples\n",
            "600000/600000 [==============================] - 232s 387us/sample - loss: 7.2819 - accuracy: 0.9602 - auc_2: 0.9656 - precision_2: 0.9604 - val_loss: 2.2820 - val_accuracy: 0.9869 - val_auc_2: 0.9901 - val_precision_2: 0.9884\n",
            "my_model_test-tpu3.h5 weights_test-tpu3.h5  are saved.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ULVcZVqSFsL",
        "colab_type": "code",
        "outputId": "650717f7-0c21-48e0-88a4-a5567540892e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 859
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "pkl_base=\"drive/My Drive/data/pickles/\"\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "model.compile(tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "          loss='binary_crossentropy',\n",
        "          metrics=['accuracy',tf.keras.metrics.AUC(),tf.keras.metrics.Precision()])\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                batch_size=128,\n",
        "                epochs=30,\n",
        "                  validation_split=.2,\n",
        "                  callbacks=[callback]\n",
        "                  )\n",
        "model_name=\"my_model_test-tpu6.h5\"\n",
        "model_weights=\"weights_test-tpu6.h5\"\n",
        "model.save(pkl_base+model_name)\n",
        "model.save_weights(pkl_base+model_weights)\n",
        "print(model_name,model_weights,\" are saved.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 480000 samples, validate on 120000 samples\n",
            "Epoch 1/30\n",
            "480000/480000 [==============================] - 240s 499us/sample - loss: 7.1064 - accuracy: 0.6970 - auc_1: 0.8024 - precision_1: 0.8299 - val_loss: 8.1311 - val_accuracy: 0.7718 - val_auc_1: 0.8786 - val_precision_1: 0.9880\n",
            "Epoch 2/30\n",
            "480000/480000 [==============================] - 237s 493us/sample - loss: 5.2074 - accuracy: 0.6999 - auc_1: 0.8032 - precision_1: 0.8625 - val_loss: 6.2345 - val_accuracy: 0.7967 - val_auc_1: 0.8845 - val_precision_1: 0.9917\n",
            "Epoch 3/30\n",
            "480000/480000 [==============================] - 237s 494us/sample - loss: 4.5177 - accuracy: 0.7078 - auc_1: 0.8124 - precision_1: 0.8805 - val_loss: 6.6920 - val_accuracy: 0.7919 - val_auc_1: 0.9196 - val_precision_1: 0.9927\n",
            "Epoch 4/30\n",
            "480000/480000 [==============================] - 240s 500us/sample - loss: 3.2733 - accuracy: 0.7008 - auc_1: 0.8018 - precision_1: 0.9309 - val_loss: 16.8144 - val_accuracy: 0.8343 - val_auc_1: 0.9236 - val_precision_1: 0.9953\n",
            "Epoch 5/30\n",
            "480000/480000 [==============================] - 237s 494us/sample - loss: 3.2235 - accuracy: 0.6851 - auc_1: 0.7907 - precision_1: 0.8495 - val_loss: 6.0651 - val_accuracy: 0.7555 - val_auc_1: 0.9026 - val_precision_1: 0.9888\n",
            "Epoch 6/30\n",
            "480000/480000 [==============================] - 241s 502us/sample - loss: 4.0952 - accuracy: 0.6925 - auc_1: 0.7931 - precision_1: 0.8948 - val_loss: 6.4254 - val_accuracy: 0.8073 - val_auc_1: 0.8834 - val_precision_1: 0.9876\n",
            "Epoch 7/30\n",
            "480000/480000 [==============================] - 238s 495us/sample - loss: 5.4024 - accuracy: 0.7072 - auc_1: 0.8142 - precision_1: 0.7339 - val_loss: 7.3439 - val_accuracy: 0.7599 - val_auc_1: 0.9117 - val_precision_1: 0.9929\n",
            "Epoch 8/30\n",
            "480000/480000 [==============================] - 238s 495us/sample - loss: 6.8100 - accuracy: 0.6975 - auc_1: 0.8094 - precision_1: 0.7368 - val_loss: 8.5597 - val_accuracy: 0.8252 - val_auc_1: 0.9321 - val_precision_1: 0.9922\n",
            "Epoch 9/30\n",
            "480000/480000 [==============================] - 238s 495us/sample - loss: 4.1205 - accuracy: 0.6942 - auc_1: 0.8028 - precision_1: 0.7957 - val_loss: 6.4505 - val_accuracy: 0.8128 - val_auc_1: 0.9076 - val_precision_1: 0.9931\n",
            "Epoch 10/30\n",
            "480000/480000 [==============================] - 237s 493us/sample - loss: 3.8644 - accuracy: 0.6901 - auc_1: 0.7946 - precision_1: 0.8655 - val_loss: 6.2276 - val_accuracy: 0.7932 - val_auc_1: 0.9169 - val_precision_1: 0.9929\n",
            "Epoch 11/30\n",
            "480000/480000 [==============================] - 239s 497us/sample - loss: 4.0484 - accuracy: 0.6928 - auc_1: 0.7947 - precision_1: 0.9044 - val_loss: 5.3609 - val_accuracy: 0.7938 - val_auc_1: 0.9069 - val_precision_1: 0.7291\n",
            "Epoch 12/30\n",
            "480000/480000 [==============================] - 236s 492us/sample - loss: 5.0927 - accuracy: 0.6877 - auc_1: 0.7972 - precision_1: 0.7230 - val_loss: 8.2195 - val_accuracy: 0.7988 - val_auc_1: 0.9241 - val_precision_1: 0.7337\n",
            "Epoch 13/30\n",
            "480000/480000 [==============================] - 236s 491us/sample - loss: 3.4299 - accuracy: 0.6852 - auc_1: 0.7915 - precision_1: 0.8036 - val_loss: 10.6913 - val_accuracy: 0.7999 - val_auc_1: 0.9144 - val_precision_1: 0.9943\n",
            "Epoch 14/30\n",
            "480000/480000 [==============================] - 236s 492us/sample - loss: 4.6600 - accuracy: 0.6823 - auc_1: 0.7834 - precision_1: 0.8603 - val_loss: 6.6168 - val_accuracy: 0.7992 - val_auc_1: 0.9048 - val_precision_1: 0.9898\n",
            "Epoch 15/30\n",
            "480000/480000 [==============================] - 236s 492us/sample - loss: 5.1367 - accuracy: 0.6861 - auc_1: 0.7880 - precision_1: 0.8839 - val_loss: 5.4407 - val_accuracy: 0.7587 - val_auc_1: 0.9038 - val_precision_1: 0.9885\n",
            "Epoch 16/30\n",
            "480000/480000 [==============================] - 237s 494us/sample - loss: 3.9208 - accuracy: 0.6825 - auc_1: 0.7876 - precision_1: 0.7845 - val_loss: 11.5373 - val_accuracy: 0.8029 - val_auc_1: 0.9137 - val_precision_1: 0.9936\n",
            "Epoch 17/30\n",
            "480000/480000 [==============================] - 238s 496us/sample - loss: 3.9090 - accuracy: 0.6823 - auc_1: 0.7829 - precision_1: 0.8615 - val_loss: 8.0061 - val_accuracy: 0.7777 - val_auc_1: 0.8947 - val_precision_1: 0.9923\n",
            "Epoch 18/30\n",
            "480000/480000 [==============================] - 238s 496us/sample - loss: 3.2976 - accuracy: 0.6790 - auc_1: 0.7730 - precision_1: 0.9343 - val_loss: 5.5900 - val_accuracy: 0.8039 - val_auc_1: 0.9109 - val_precision_1: 0.9910\n",
            "Epoch 19/30\n",
            "480000/480000 [==============================] - 238s 497us/sample - loss: 4.9201 - accuracy: 0.6774 - auc_1: 0.7726 - precision_1: 0.8938 - val_loss: 14.9280 - val_accuracy: 0.7956 - val_auc_1: 0.9123 - val_precision_1: 0.9913\n",
            "Epoch 20/30\n",
            "480000/480000 [==============================] - 239s 498us/sample - loss: 3.8446 - accuracy: 0.6812 - auc_1: 0.7847 - precision_1: 0.8342 - val_loss: 10.0042 - val_accuracy: 0.7481 - val_auc_1: 0.8859 - val_precision_1: 0.9935\n",
            "Epoch 21/30\n",
            "480000/480000 [==============================] - 239s 499us/sample - loss: 7.3218 - accuracy: 0.6763 - auc_1: 0.7811 - precision_1: 0.7751 - val_loss: 20.7843 - val_accuracy: 0.7778 - val_auc_1: 0.8999 - val_precision_1: 0.9931\n",
            "my_model_test-tpu6.h5 weights_test-tpu6.h5  are saved.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Hlw5HLqquKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}